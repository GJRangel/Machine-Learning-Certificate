{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline\n",
       "0             1  thirtysomething scientists unveil doomsday clo...\n",
       "1             0  dem rep. totally nails why congress is falling...\n",
       "2             0  eat your veggies: 9 deliciously different recipes\n",
       "3             1  inclement weather prevents liar from getting t...\n",
       "4             1  mother comes pretty close to using word 'strea..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main packages \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data\n",
    "data = pd.read_json('data/Sarcasm-Detection/Sarcasm_Headlines_Dataset_v2.json', lines=True)\n",
    "data.drop(columns='article_link', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is it balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.476396799329117"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_sarcastic'].sum()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, not exactly but around half of the sentences are sarcasm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>[thirtysomething, scientists, unveil, doomsday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>[dem, rep, ., totally, nails, why, congress, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>[eat, your, veggies, 9, deliciously, different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>[inclement, weather, prevents, liar, from, get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>[mother, comes, pretty, close, to, using, word...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [thirtysomething, scientists, unveil, doomsday...  \n",
       "1  [dem, rep, ., totally, nails, why, congress, i...  \n",
       "2  [eat, your, veggies, 9, deliciously, different...  \n",
       "3  [inclement, weather, prevents, liar, from, get...  \n",
       "4  [mother, comes, pretty, close, to, using, word...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "def tokenize(text):\n",
    "    return tokenizer(text)\n",
    "\n",
    "data['tokens'] = data['headline'].apply(tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for sentence in data_iter:\n",
    "        yield tokenize(sentence)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(data['headline']), specials = ['<unk>', '<pad>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert tokens to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>tokens</th>\n",
       "      <th>numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>[thirtysomething, scientists, unveil, doomsday...</td>\n",
       "      <td>[27581, 356, 3312, 6539, 2127, 4, 685, 1173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>[dem, rep, ., totally, nails, why, congress, i...</td>\n",
       "      <td>[7676, 1659, 12, 745, 3238, 55, 241, 16, 1926,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>[eat, your, veggies, 9, deliciously, different...</td>\n",
       "      <td>[917, 43, 15110, 604, 18819, 614, 1499]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>[inclement, weather, prevents, liar, from, get...</td>\n",
       "      <td>[13039, 1677, 6968, 4733, 19, 149, 3, 158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>[mother, comes, pretty, close, to, using, word...</td>\n",
       "      <td>[284, 489, 301, 1016, 3, 578, 634, 2, 4438, 2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [thirtysomething, scientists, unveil, doomsday...   \n",
       "1  [dem, rep, ., totally, nails, why, congress, i...   \n",
       "2  [eat, your, veggies, 9, deliciously, different...   \n",
       "3  [inclement, weather, prevents, liar, from, get...   \n",
       "4  [mother, comes, pretty, close, to, using, word...   \n",
       "\n",
       "                                           numerical  \n",
       "0       [27581, 356, 3312, 6539, 2127, 4, 685, 1173]  \n",
       "1  [7676, 1659, 12, 745, 3238, 55, 241, 16, 1926,...  \n",
       "2            [917, 43, 15110, 604, 18819, 614, 1499]  \n",
       "3         [13039, 1677, 6968, 4733, 19, 149, 3, 158]  \n",
       "4  [284, 489, 301, 1016, 3, 578, 634, 2, 4438, 2,...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['numerical'] = data['tokens'].apply(lambda x: vocab(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[27581,   356,  3312,  ...,     0,     0,     0],\n",
       "         [ 7676,  1659,    12,  ...,     0,     0,     0],\n",
       "         [  917,    43, 15110,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    6,   103,   598,  ...,     0,     0,     0],\n",
       "         [ 1866,  1210,  3166,  ...,     0,     0,     0],\n",
       "         [  191,  3152,    27,  ...,     0,     0,     0]]),\n",
       " torch.Size([28619, 166]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def pad_sequences(sequences, padding_value = 0):\n",
    "    return pad_sequence([torch.tensor(seq) for seq in sequences], batch_first=True, padding_value=padding_value)\n",
    "padded_sequences = pad_sequences(data['numerical'].tolist())\n",
    "padded_sequences, padded_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20033, 5752, 2834)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, data['is_sarcastic'].values, test_size = 0.3)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.33)\n",
    "\n",
    "X_train.shape[0], X_test.shape[0], X_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, input, labels):\n",
    "        self.input = input\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.input[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        non_pad = (input != 0).sum()\n",
    "        \n",
    "        \n",
    "        return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Instantiate the dataset\n",
    "train_dataset = SarcasmDataset(X_train, y_train)\n",
    "val_dataset = SarcasmDataset(X_val, y_val)\n",
    "test_dataset = SarcasmDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RNN model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "class SarcsmDetectorV1(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers = 1):\n",
    "        super(SarcsmDetectorV1, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "         # Pack the sequences\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, h_n = self.rnn(packed_input)\n",
    "        \n",
    "        # Unpack the sequences\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        h_n = h_n[-1]\n",
    "        out = self.fc(h_n)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Hyper parameters  \n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 100\n",
    "hidden_dim = 200\n",
    "output_dim = 1\n",
    "\n",
    "# agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "rnn0 = SarcsmDetectorV1(vocab_size, embed_dim, hidden_dim, output_dim, num_layers=1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(rnn0.parameters(), lr = 0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n",
      "100%|██████████| 313/313 [00:04<00:00, 74.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.6556 | Train Acc: 58.95% | Val Loss: 0.5833 | Val Acc: 68.00%\n",
      "Saving model with loss: 0.5833211161873557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.5640 | Train Acc: 70.73% | Val Loss: 0.5510 | Val Acc: 71.56%\n",
      "Saving model with loss: 0.5509734478863803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.5365 | Train Acc: 73.00% | Val Loss: 0.5343 | Val Acc: 72.19%\n",
      "Saving model with loss: 0.5342639081857421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.5114 | Train Acc: 74.85% | Val Loss: 0.5234 | Val Acc: 73.69%\n",
      "Saving model with loss: 0.5234032246199521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.4879 | Train Acc: 76.47% | Val Loss: 0.5005 | Val Acc: 74.86%\n",
      "Saving model with loss: 0.5004627880724993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.4651 | Train Acc: 78.06% | Val Loss: 0.4910 | Val Acc: 75.67%\n",
      "Saving model with loss: 0.4910289699381048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 0.4433 | Train Acc: 79.35% | Val Loss: 0.4832 | Val Acc: 76.24%\n",
      "Saving model with loss: 0.48322479968721216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 0.4238 | Train Acc: 80.70% | Val Loss: 0.4786 | Val Acc: 75.96%\n",
      "Saving model with loss: 0.4786287166855552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 0.4042 | Train Acc: 81.76% | Val Loss: 0.4658 | Val Acc: 77.02%\n",
      "Saving model with loss: 0.4658035365017978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 0.3850 | Train Acc: 82.78% | Val Loss: 0.4553 | Val Acc: 77.88%\n",
      "Saving model with loss: 0.4553419351577759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 0.3643 | Train Acc: 84.00% | Val Loss: 0.4486 | Val Acc: 78.12%\n",
      "Saving model with loss: 0.4485705582932992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 0.3459 | Train Acc: 84.90% | Val Loss: 0.4434 | Val Acc: 78.16%\n",
      "Saving model with loss: 0.4434040805155581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 0.3298 | Train Acc: 86.00% | Val Loss: 0.4386 | Val Acc: 79.58%\n",
      "Saving model with loss: 0.43858146836811845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 80.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 0.3100 | Train Acc: 86.91% | Val Loss: 0.4431 | Val Acc: 79.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 0.2927 | Train Acc: 87.85% | Val Loss: 0.4353 | Val Acc: 79.72%\n",
      "Saving model with loss: 0.4353467056697065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 0.2782 | Train Acc: 88.30% | Val Loss: 0.4392 | Val Acc: 79.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 0.2621 | Train Acc: 89.08% | Val Loss: 0.4498 | Val Acc: 80.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 78.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss: 0.2473 | Train Acc: 90.02% | Val Loss: 0.4489 | Val Acc: 80.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss: 0.2307 | Train Acc: 90.90% | Val Loss: 0.4690 | Val Acc: 81.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss: 0.2151 | Train Acc: 91.43% | Val Loss: 0.4620 | Val Acc: 80.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss: 0.1812 | Train Acc: 93.28% | Val Loss: 0.4523 | Val Acc: 81.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss: 0.1729 | Train Acc: 93.63% | Val Loss: 0.4540 | Val Acc: 81.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss: 0.1695 | Train Acc: 93.76% | Val Loss: 0.4605 | Val Acc: 81.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 78.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss: 0.1668 | Train Acc: 93.86% | Val Loss: 0.4738 | Val Acc: 81.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss: 0.1644 | Train Acc: 93.93% | Val Loss: 0.4670 | Val Acc: 81.39%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "num_epochs = 100\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "max_count = 10\n",
    "for epoch in range(num_epochs):\n",
    "    rnn0.train()\n",
    "    avg_train_loss = 0\n",
    "    train_acc = 0\n",
    "    for inputs, labels, lengths in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn0(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        avg_train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        train_acc += (outputs.round() == labels).sum().item()/len(labels)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc /= len(train_dataloader)\n",
    "    avg_train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Validate\n",
    "    avg_val_loss = 0\n",
    "    val_acc = 0\n",
    "    rnn0.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in val_dataloader:\n",
    "            inputs, labels = inputs.to(device) , labels.to(device)\n",
    "            \n",
    "            # Prediction\n",
    "            outputs = rnn0(inputs, lengths).squeeze()\n",
    "            \n",
    "            # Calculate and acumulate loss\n",
    "            loss = loss_fn(outputs, labels.float())\n",
    "            avg_val_loss += loss.item()\n",
    "\n",
    "            # Calculate acc\n",
    "            val_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "        val_acc /= len(val_dataloader)\n",
    "        avg_val_loss /= len(val_dataloader)\n",
    "    \n",
    "    print(f'Epoch: {epoch} | Train Loss: {avg_train_loss:.4f} | Train Acc: {100*train_acc:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(rnn0.state_dict(), 'Saved Models/Sarcasm Det Models/best_rnn0.pth')\n",
    "        print(f'Saving model with loss: {avg_val_loss}')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter == max_count:\n",
    "        break\n",
    "    scheduler.step(avg_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn0.load_state_dict(torch.load('Saved Models/Sarcasm Det Models/best_rnn0.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN0:\n",
      "     Test Loss: 0.44397397389572657 | Test Acc:0.7970505617977528\n"
     ]
    }
   ],
   "source": [
    "rnn0.eval()\n",
    "rnn0_test_loss = 0\n",
    "rnn0_test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, lengths in test_dataloader:\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn0(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        rnn0_test_loss += loss.item()\n",
    "\n",
    "        # Calculate acc\n",
    "        rnn0_test_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "    rnn0_test_acc /= len(test_dataloader)\n",
    "    rnn0_test_loss /= len(test_dataloader)\n",
    "print(f'RNN0:')\n",
    "print(f'     Test Loss: {rnn0_test_loss} | Test Acc:{rnn0_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model is slightly overfitting, lets try to add drops for regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add dropout regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcsmDetectorV2(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers = 1, p_drop = 0.2):\n",
    "        super(SarcsmDetectorV2, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p_drop)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "         # Pack the sequences\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, h_n = self.rnn(packed_input)\n",
    "        \n",
    "        h_n = h_n[-1]\n",
    "        h_n = self.dropout(h_n)\n",
    "        out = self.fc(h_n)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n",
      "100%|██████████| 313/313 [00:03<00:00, 82.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.6912 | Train Acc: 53.95% | Val Loss: 0.6490 | Val Acc: 61.65%\n",
      "Saving model with loss: 0.6490102992816404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.6228 | Train Acc: 65.38% | Val Loss: 0.5766 | Val Acc: 70.24%\n",
      "Saving model with loss: 0.5766388577493754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 78.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.5973 | Train Acc: 68.20% | Val Loss: 0.5652 | Val Acc: 71.34%\n",
      "Saving model with loss: 0.5651861700144681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.5823 | Train Acc: 69.37% | Val Loss: 0.5594 | Val Acc: 71.95%\n",
      "Saving model with loss: 0.5594189180569216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.5697 | Train Acc: 70.42% | Val Loss: 0.5668 | Val Acc: 72.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 81.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.5581 | Train Acc: 71.31% | Val Loss: 0.5449 | Val Acc: 72.69%\n",
      "Saving model with loss: 0.5448576740243218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 0.5459 | Train Acc: 72.04% | Val Loss: 0.5320 | Val Acc: 74.11%\n",
      "Saving model with loss: 0.531990608708425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 0.5357 | Train Acc: 72.83% | Val Loss: 0.5280 | Val Acc: 74.43%\n",
      "Saving model with loss: 0.5280227207324721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 0.5235 | Train Acc: 73.78% | Val Loss: 0.5348 | Val Acc: 74.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 0.5065 | Train Acc: 74.69% | Val Loss: 0.5080 | Val Acc: 75.82%\n",
      "Saving model with loss: 0.5080201625823975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 81.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 0.4998 | Train Acc: 75.50% | Val Loss: 0.5105 | Val Acc: 75.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 0.4878 | Train Acc: 76.02% | Val Loss: 0.4883 | Val Acc: 76.60%\n",
      "Saving model with loss: 0.48830711299722845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 0.4840 | Train Acc: 76.59% | Val Loss: 0.4855 | Val Acc: 77.20%\n",
      "Saving model with loss: 0.4855275519869544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 0.4706 | Train Acc: 77.52% | Val Loss: 0.4758 | Val Acc: 77.13%\n",
      "Saving model with loss: 0.475813435559923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 0.4625 | Train Acc: 77.95% | Val Loss: 0.4774 | Val Acc: 78.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 0.4516 | Train Acc: 78.84% | Val Loss: 0.4746 | Val Acc: 78.20%\n",
      "Saving model with loss: 0.4745804965496063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 81.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 0.4441 | Train Acc: 78.82% | Val Loss: 0.4549 | Val Acc: 78.84%\n",
      "Saving model with loss: 0.45493000000715256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss: 0.4386 | Train Acc: 79.18% | Val Loss: 0.4648 | Val Acc: 78.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss: 0.4299 | Train Acc: 79.91% | Val Loss: 0.4405 | Val Acc: 79.94%\n",
      "Saving model with loss: 0.4405497590249235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 80.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss: 0.4171 | Train Acc: 80.45% | Val Loss: 0.4399 | Val Acc: 79.40%\n",
      "Saving model with loss: 0.43988846106962726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss: 0.4141 | Train Acc: 80.76% | Val Loss: 0.4328 | Val Acc: 79.87%\n",
      "Saving model with loss: 0.43281158872626047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss: 0.4091 | Train Acc: 81.50% | Val Loss: 0.4426 | Val Acc: 80.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 80.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss: 0.4032 | Train Acc: 81.61% | Val Loss: 0.4332 | Val Acc: 80.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 81.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss: 0.3997 | Train Acc: 81.65% | Val Loss: 0.4164 | Val Acc: 80.40%\n",
      "Saving model with loss: 0.41642245379361237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 80.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss: 0.3947 | Train Acc: 81.84% | Val Loss: 0.4120 | Val Acc: 81.21%\n",
      "Saving model with loss: 0.41202966936609964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train Loss: 0.3800 | Train Acc: 82.55% | Val Loss: 0.4347 | Val Acc: 80.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train Loss: 0.3761 | Train Acc: 83.05% | Val Loss: 0.4170 | Val Acc: 81.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train Loss: 0.3688 | Train Acc: 83.54% | Val Loss: 0.4144 | Val Acc: 81.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 80.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train Loss: 0.3674 | Train Acc: 83.36% | Val Loss: 0.4138 | Val Acc: 81.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 81.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Train Loss: 0.3610 | Train Acc: 83.77% | Val Loss: 0.4228 | Val Acc: 80.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 80.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Train Loss: 0.3483 | Train Acc: 84.45% | Val Loss: 0.4112 | Val Acc: 81.46%\n",
      "Saving model with loss: 0.41119555790315976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Train Loss: 0.3461 | Train Acc: 84.58% | Val Loss: 0.4091 | Val Acc: 81.32%\n",
      "Saving model with loss: 0.4090628962625157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Train Loss: 0.3452 | Train Acc: 84.79% | Val Loss: 0.4134 | Val Acc: 81.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Train Loss: 0.3415 | Train Acc: 84.57% | Val Loss: 0.4105 | Val Acc: 81.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 82.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Train Loss: 0.3412 | Train Acc: 84.90% | Val Loss: 0.4081 | Val Acc: 81.96%\n",
      "Saving model with loss: 0.40813352912664413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 80.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Train Loss: 0.3417 | Train Acc: 84.86% | Val Loss: 0.4074 | Val Acc: 81.78%\n",
      "Saving model with loss: 0.40743359652432526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Train Loss: 0.3382 | Train Acc: 85.08% | Val Loss: 0.4131 | Val Acc: 82.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Train Loss: 0.3400 | Train Acc: 85.02% | Val Loss: 0.4062 | Val Acc: 81.92%\n",
      "Saving model with loss: 0.40623976357958536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 81.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Train Loss: 0.3399 | Train Acc: 85.12% | Val Loss: 0.4102 | Val Acc: 82.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | Train Loss: 0.3380 | Train Acc: 85.03% | Val Loss: 0.4024 | Val Acc: 82.07%\n",
      "Saving model with loss: 0.4023651304570111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Train Loss: 0.3391 | Train Acc: 85.02% | Val Loss: 0.4044 | Val Acc: 81.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | Train Loss: 0.3356 | Train Acc: 85.17% | Val Loss: 0.4128 | Val Acc: 81.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 81.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | Train Loss: 0.3338 | Train Acc: 85.36% | Val Loss: 0.4142 | Val Acc: 82.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 83.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | Train Loss: 0.3377 | Train Acc: 85.16% | Val Loss: 0.4074 | Val Acc: 82.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 82.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 | Train Loss: 0.3351 | Train Acc: 85.18% | Val Loss: 0.4105 | Val Acc: 82.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 80.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 | Train Loss: 0.3329 | Train Acc: 85.48% | Val Loss: 0.4083 | Val Acc: 82.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 81.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Train Loss: 0.3349 | Train Acc: 85.50% | Val Loss: 0.4081 | Val Acc: 82.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 82.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 | Train Loss: 0.3311 | Train Acc: 85.49% | Val Loss: 0.4089 | Val Acc: 82.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Train Loss: 0.3314 | Train Acc: 85.50% | Val Loss: 0.4078 | Val Acc: 82.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 81.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 | Train Loss: 0.3324 | Train Acc: 85.53% | Val Loss: 0.4096 | Val Acc: 82.07%\n"
     ]
    }
   ],
   "source": [
    "rnn1 = SarcsmDetectorV2(vocab_size, embed_dim, hidden_dim, output_dim, p_drop=0.4).to(device)\n",
    "optimizer = torch.optim.Adam(rnn1.parameters(), lr = 0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "max_count = 10\n",
    "for epoch in range(num_epochs):\n",
    "    rnn1.train()\n",
    "    avg_train_loss = 0\n",
    "    train_acc = 0\n",
    "    for inputs, labels, lengths in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn1(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        avg_train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        train_acc += (outputs.round() == labels).sum().item()/len(labels)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc /= len(train_dataloader)\n",
    "    avg_train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Validate\n",
    "    avg_val_loss = 0\n",
    "    val_acc = 0\n",
    "    rnn1.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in val_dataloader:\n",
    "            inputs, labels = inputs.to(device) , labels.to(device)\n",
    "            \n",
    "            # Prediction\n",
    "            outputs = rnn1(inputs, lengths).squeeze()\n",
    "            \n",
    "            # Calculate and acumulate loss\n",
    "            loss = loss_fn(outputs, labels.float())\n",
    "            avg_val_loss += loss.item()\n",
    "\n",
    "            # Calculate acc\n",
    "            val_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "        val_acc /= len(val_dataloader)\n",
    "        avg_val_loss /= len(val_dataloader)\n",
    "    \n",
    "    print(f'Epoch: {epoch} | Train Loss: {avg_train_loss:.4f} | Train Acc: {100*train_acc:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(rnn1.state_dict(), 'Saved Models/Sarcasm Det Models/best_rnn1.pth')\n",
    "        print(f'Saving model with loss: {avg_val_loss}')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter == max_count:\n",
    "        break\n",
    "    scheduler.step(avg_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn1:\n",
      "     Test Loss: 0.3986469897326459 | Test Acc:0.8258426966292135\n"
     ]
    }
   ],
   "source": [
    "rnn1.load_state_dict(torch.load('Saved Models/Sarcasm Det Models/best_rnn1.pth'))\n",
    "\n",
    "rnn1.eval()\n",
    "rnn1_test_loss = 0\n",
    "rnn1_test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, lengths in test_dataloader:\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn1(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        rnn1_test_loss += loss.item()\n",
    "\n",
    "        # Calculate acc\n",
    "        rnn1_test_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "    rnn1_test_acc /= len(test_dataloader)\n",
    "    rnn1_test_loss /= len(test_dataloader)\n",
    "print(f'rnn1:')\n",
    "print(f'     Test Loss: {rnn1_test_loss} | Test Acc:{rnn1_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcsmDetectorV3(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers = 1, p_drop = 0.2):\n",
    "        super(SarcsmDetectorV3, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p_drop)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "         # Pack the sequences\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, _) = self.lstm(packed_input)\n",
    "\n",
    "        h_n = h_n[-1]\n",
    "        h_n = self.dropout(h_n)\n",
    "        out = self.fc(h_n)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM model (No dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n",
      "100%|██████████| 313/313 [00:04<00:00, 77.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.6457 | Train Acc: 62.18% | Val Loss: 24.8670 | Val Acc: 71.41%\n",
      "Saving model with loss: 24.866981148719788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.5267 | Train Acc: 73.48% | Val Loss: 22.5499 | Val Acc: 75.14%\n",
      "Saving model with loss: 22.54989179968834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.4723 | Train Acc: 77.11% | Val Loss: 20.9356 | Val Acc: 77.45%\n",
      "Saving model with loss: 20.935552954673767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.4222 | Train Acc: 80.42% | Val Loss: 19.6105 | Val Acc: 78.55%\n",
      "Saving model with loss: 19.61047601699829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.3792 | Train Acc: 83.14% | Val Loss: 18.6726 | Val Acc: 79.94%\n",
      "Saving model with loss: 18.67260731756687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.3425 | Train Acc: 84.97% | Val Loss: 18.0080 | Val Acc: 81.29%\n",
      "Saving model with loss: 18.008045434951782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 0.3121 | Train Acc: 86.56% | Val Loss: 17.8722 | Val Acc: 82.17%\n",
      "Saving model with loss: 17.872244864702225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 0.2830 | Train Acc: 88.30% | Val Loss: 18.1141 | Val Acc: 81.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 0.2575 | Train Acc: 89.58% | Val Loss: 18.3368 | Val Acc: 82.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 0.2337 | Train Acc: 90.62% | Val Loss: 18.6682 | Val Acc: 82.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 0.2135 | Train Acc: 91.57% | Val Loss: 19.4007 | Val Acc: 82.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 0.1933 | Train Acc: 92.55% | Val Loss: 20.0505 | Val Acc: 82.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 78.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 0.1751 | Train Acc: 93.33% | Val Loss: 21.1386 | Val Acc: 82.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 0.1566 | Train Acc: 94.05% | Val Loss: 21.5987 | Val Acc: 82.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 78.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 0.1416 | Train Acc: 94.82% | Val Loss: 23.7694 | Val Acc: 82.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 78.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 0.1288 | Train Acc: 95.45% | Val Loss: 23.8997 | Val Acc: 82.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 0.1140 | Train Acc: 95.96% | Val Loss: 25.4554 | Val Acc: 82.14%\n"
     ]
    }
   ],
   "source": [
    "rnn2 = SarcsmDetectorV3(vocab_size, embed_dim, hidden_dim, output_dim, p_drop=0.0).to(device)\n",
    "optimizer = torch.optim.Adam(rnn2.parameters(), lr = 0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "max_count = 10\n",
    "for epoch in range(num_epochs):\n",
    "    rnn2.train()\n",
    "    avg_train_loss = 0\n",
    "    train_acc = 0\n",
    "    for inputs, labels, lengths in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn2(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        avg_train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        train_acc += (outputs.round() == labels).sum().item()/len(labels)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc /= len(train_dataloader)\n",
    "    avg_train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Validate\n",
    "    avg_val_loss = 0\n",
    "    val_acc = 0\n",
    "    rnn2.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in val_dataloader:\n",
    "            inputs, labels = inputs.to(device) , labels.to(device)\n",
    "            \n",
    "            # Prediction\n",
    "            outputs = rnn2(inputs, lengths).squeeze()\n",
    "            \n",
    "            # Calculate and acumulate loss\n",
    "            loss = loss_fn(outputs, labels.float())\n",
    "            avg_val_loss += loss.item()\n",
    "\n",
    "            # Calculate acc\n",
    "            val_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "        val_acc /= len(val_dataloader)\n",
    "    \n",
    "    print(f'Epoch: {epoch} | Train Loss: {avg_train_loss:.4f} | Train Acc: {100*train_acc:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(rnn2.state_dict(), 'Saved Models/Sarcasm Det Models/best_rnn2.pth')\n",
    "        print(f'Saving model with loss: {avg_val_loss}')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter == max_count:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn2:\n",
      "     Test Loss: 0.3904631879557385 | Test Acc:0.8277738764044944\n"
     ]
    }
   ],
   "source": [
    "rnn2.load_state_dict(torch.load('Saved Models/Sarcasm Det Models/best_rnn2.pth'))\n",
    "\n",
    "rnn2.eval()\n",
    "rnn2_test_loss = 0\n",
    "rnn2_test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, lengths in test_dataloader:\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn2(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        rnn2_test_loss += loss.item()\n",
    "\n",
    "        # Calculate acc\n",
    "        rnn2_test_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "    rnn2_test_acc /= len(test_dataloader)\n",
    "    rnn2_test_loss /= len(test_dataloader)\n",
    "print(f'rnn2:')\n",
    "print(f'     Test Loss: {rnn2_test_loss} | Test Acc:{rnn2_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add dropout to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n",
      "100%|██████████| 313/313 [00:04<00:00, 76.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.6850 | Train Acc: 54.63% | Val Loss: 0.6481 | Val Acc: 62.39%\n",
      "Saving model with loss: 0.648052147843621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.6032 | Train Acc: 67.53% | Val Loss: 0.5411 | Val Acc: 71.91%\n",
      "Saving model with loss: 0.5410558141090653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.5528 | Train Acc: 71.48% | Val Loss: 0.5066 | Val Acc: 74.04%\n",
      "Saving model with loss: 0.5065722756765105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 73.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.5159 | Train Acc: 74.28% | Val Loss: 0.4777 | Val Acc: 75.60%\n",
      "Saving model with loss: 0.4776552780108018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.4843 | Train Acc: 76.50% | Val Loss: 0.4551 | Val Acc: 77.88%\n",
      "Saving model with loss: 0.4550791931423274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.4568 | Train Acc: 78.27% | Val Loss: 0.4388 | Val Acc: 79.44%\n",
      "Saving model with loss: 0.4387854987924749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 0.4396 | Train Acc: 79.21% | Val Loss: 0.4290 | Val Acc: 80.43%\n",
      "Saving model with loss: 0.42895813286304474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 0.4283 | Train Acc: 79.88% | Val Loss: 0.4134 | Val Acc: 80.97%\n",
      "Saving model with loss: 0.41340812837535684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 0.4118 | Train Acc: 81.00% | Val Loss: 0.4078 | Val Acc: 81.32%\n",
      "Saving model with loss: 0.40781780129129236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 0.4051 | Train Acc: 81.40% | Val Loss: 0.4108 | Val Acc: 81.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 0.3950 | Train Acc: 82.10% | Val Loss: 0.3997 | Val Acc: 82.32%\n",
      "Saving model with loss: 0.3996831439435482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 0.3825 | Train Acc: 82.60% | Val Loss: 0.3933 | Val Acc: 82.17%\n",
      "Saving model with loss: 0.3932744698090987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 0.3769 | Train Acc: 82.93% | Val Loss: 0.3856 | Val Acc: 82.56%\n",
      "Saving model with loss: 0.38562585887583817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 0.3685 | Train Acc: 83.29% | Val Loss: 0.3801 | Val Acc: 82.95%\n",
      "Saving model with loss: 0.38009070909836074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 0.3612 | Train Acc: 84.00% | Val Loss: 0.3922 | Val Acc: 83.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 0.3512 | Train Acc: 84.59% | Val Loss: 0.3985 | Val Acc: 83.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 0.3473 | Train Acc: 84.49% | Val Loss: 0.3743 | Val Acc: 83.56%\n",
      "Saving model with loss: 0.37431942705403676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss: 0.3424 | Train Acc: 84.64% | Val Loss: 0.3699 | Val Acc: 83.74%\n",
      "Saving model with loss: 0.3699305101551793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss: 0.3329 | Train Acc: 85.24% | Val Loss: 0.3687 | Val Acc: 84.73%\n",
      "Saving model with loss: 0.36874090507626534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss: 0.3269 | Train Acc: 85.74% | Val Loss: 0.3669 | Val Acc: 84.23%\n",
      "Saving model with loss: 0.36688587679104373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 73.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss: 0.3254 | Train Acc: 85.76% | Val Loss: 0.3885 | Val Acc: 84.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 72.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss: 0.3186 | Train Acc: 86.01% | Val Loss: 0.3724 | Val Acc: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss: 0.3096 | Train Acc: 86.56% | Val Loss: 0.3859 | Val Acc: 84.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss: 0.3078 | Train Acc: 86.95% | Val Loss: 0.3701 | Val Acc: 84.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss: 0.3035 | Train Acc: 87.13% | Val Loss: 0.3684 | Val Acc: 84.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train Loss: 0.2956 | Train Acc: 87.28% | Val Loss: 0.3725 | Val Acc: 84.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train Loss: 0.2929 | Train Acc: 87.22% | Val Loss: 0.3713 | Val Acc: 84.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train Loss: 0.2889 | Train Acc: 87.61% | Val Loss: 0.3797 | Val Acc: 84.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train Loss: 0.2866 | Train Acc: 87.75% | Val Loss: 0.3731 | Val Acc: 84.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Train Loss: 0.2781 | Train Acc: 87.91% | Val Loss: 0.3797 | Val Acc: 84.48%\n"
     ]
    }
   ],
   "source": [
    "rnn3 = SarcsmDetectorV3(vocab_size, embed_dim, hidden_dim, output_dim, p_drop=0.4).to(device)\n",
    "optimizer = torch.optim.Adam(rnn3.parameters(), lr = 0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "max_count = 10\n",
    "for epoch in range(num_epochs):\n",
    "    rnn3.train()\n",
    "    avg_train_loss = 0\n",
    "    train_acc = 0\n",
    "    for inputs, labels, lengths in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn3(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        avg_train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        train_acc += (outputs.round() == labels).sum().item()/len(labels)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc /= len(train_dataloader)\n",
    "    avg_train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Validate\n",
    "    avg_val_loss = 0\n",
    "    val_acc = 0\n",
    "    rnn3.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in val_dataloader:\n",
    "            inputs, labels = inputs.to(device) , labels.to(device)\n",
    "            \n",
    "            # Prediction\n",
    "            outputs = rnn3(inputs, lengths).squeeze()\n",
    "            \n",
    "            # Calculate and acumulate loss\n",
    "            loss = loss_fn(outputs, labels.float())\n",
    "            avg_val_loss += loss.item()\n",
    "\n",
    "            # Calculate acc\n",
    "            val_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "        val_acc /= len(val_dataloader)\n",
    "        avg_val_loss /= len(val_dataloader)\n",
    "    \n",
    "    print(f'Epoch: {epoch} | Train Loss: {avg_train_loss:.4f} | Train Acc: {100*train_acc:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(rnn3.state_dict(), 'Saved Models/Sarcasm Det Models/best_rnn3.pth')\n",
    "        print(f'Saving model with loss: {avg_val_loss}')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter == max_count:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn3:\n",
      "     Test Loss: 0.3959961657443743 | Test Acc:0.839185393258427\n"
     ]
    }
   ],
   "source": [
    "rnn3.load_state_dict(torch.load('Saved Models/Sarcasm Det Models/best_rnn3.pth'))\n",
    "\n",
    "rnn3.eval()\n",
    "rnn3_test_loss = 0\n",
    "rnn3_test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, lengths in test_dataloader:\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn3(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        rnn3_test_loss += loss.item()\n",
    "\n",
    "        # Calculate acc\n",
    "        rnn3_test_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "    rnn3_test_acc /= len(test_dataloader)\n",
    "    rnn3_test_loss /= len(test_dataloader)\n",
    "print(f'rnn3:')\n",
    "print(f'     Test Loss: {rnn3_test_loss} | Test Acc:{rnn3_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcsmDetectorV4(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers = 1, p_drop = 0.2):\n",
    "        super(SarcsmDetectorV4, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p_drop)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "         # Pack the sequences\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, h_n = self.gru(packed_input)\n",
    "        \n",
    "        h_n = h_n[-1]\n",
    "        h_n = self.dropout(h_n)\n",
    "        out = self.fc(h_n)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n",
      "100%|██████████| 313/313 [00:03<00:00, 78.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.6458 | Train Acc: 61.12% | Val Loss: 0.5732 | Val Acc: 69.18%\n",
      "Saving model with loss: 0.5732261206616055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.5351 | Train Acc: 72.75% | Val Loss: 0.5214 | Val Acc: 72.62%\n",
      "Saving model with loss: 0.5214297906918959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.4771 | Train Acc: 76.87% | Val Loss: 0.4756 | Val Acc: 76.10%\n",
      "Saving model with loss: 0.47557748380032455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.4253 | Train Acc: 80.22% | Val Loss: 0.4421 | Val Acc: 78.80%\n",
      "Saving model with loss: 0.4420756839893081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 80.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.3814 | Train Acc: 82.97% | Val Loss: 0.4287 | Val Acc: 79.87%\n",
      "Saving model with loss: 0.42871524732221256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.3470 | Train Acc: 84.99% | Val Loss: 0.4180 | Val Acc: 81.00%\n",
      "Saving model with loss: 0.4180160476402803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 0.3196 | Train Acc: 86.08% | Val Loss: 0.4148 | Val Acc: 80.89%\n",
      "Saving model with loss: 0.4147660711949522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 71.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 0.2902 | Train Acc: 88.00% | Val Loss: 0.4256 | Val Acc: 81.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 71.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 0.2659 | Train Acc: 88.99% | Val Loss: 0.4499 | Val Acc: 81.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 0.2453 | Train Acc: 89.91% | Val Loss: 0.4547 | Val Acc: 81.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 0.2264 | Train Acc: 90.78% | Val Loss: 0.4555 | Val Acc: 81.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 73.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 0.2079 | Train Acc: 91.56% | Val Loss: 0.4582 | Val Acc: 80.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 73.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 0.1881 | Train Acc: 92.54% | Val Loss: 0.4791 | Val Acc: 81.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 0.1708 | Train Acc: 93.44% | Val Loss: 0.5167 | Val Acc: 80.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 72.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 0.1568 | Train Acc: 93.97% | Val Loss: 0.5339 | Val Acc: 81.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 0.1403 | Train Acc: 94.87% | Val Loss: 0.5573 | Val Acc: 80.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 0.1273 | Train Acc: 95.22% | Val Loss: 0.5628 | Val Acc: 80.86%\n"
     ]
    }
   ],
   "source": [
    "rnn4 = SarcsmDetectorV4(vocab_size, embed_dim, hidden_dim, output_dim, p_drop=0.0).to(device)\n",
    "optimizer = torch.optim.Adam(rnn4.parameters(), lr = 0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "max_count = 10\n",
    "for epoch in range(num_epochs):\n",
    "    rnn4.train()\n",
    "    avg_train_loss = 0\n",
    "    train_acc = 0\n",
    "    for inputs, labels, lengths in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn4(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        avg_train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        train_acc += (outputs.round() == labels).sum().item()/len(labels)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc /= len(train_dataloader)\n",
    "    avg_train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Validate\n",
    "    avg_val_loss = 0\n",
    "    val_acc = 0\n",
    "    rnn4.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in val_dataloader:\n",
    "            inputs, labels = inputs.to(device) , labels.to(device)\n",
    "            \n",
    "            # Prediction\n",
    "            outputs = rnn4(inputs, lengths).squeeze()\n",
    "            \n",
    "            # Calculate and acumulate loss\n",
    "            loss = loss_fn(outputs, labels.float())\n",
    "            avg_val_loss += loss.item()\n",
    "\n",
    "            # Calculate acc\n",
    "            val_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "        val_acc /= len(val_dataloader)\n",
    "        avg_val_loss /= len(val_dataloader)\n",
    "    print(f'Epoch: {epoch} | Train Loss: {avg_train_loss:.4f} | Train Acc: {100*train_acc:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(rnn4.state_dict(), 'Saved Models/Sarcasm Det Models/best_rnn4.pth')\n",
    "        print(f'Saving model with loss: {avg_val_loss}')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter == max_count:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn4:\n",
      "     Test Loss: 0.4009262062190624 | Test Acc:0.8158356741573034\n"
     ]
    }
   ],
   "source": [
    "rnn4.load_state_dict(torch.load('Saved Models/Sarcasm Det Models/best_rnn4.pth'))\n",
    "\n",
    "rnn4.eval()\n",
    "rnn4_test_loss = 0\n",
    "rnn4_test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, lengths in test_dataloader:\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn4(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        rnn4_test_loss += loss.item()\n",
    "\n",
    "        # Calculate acc\n",
    "        rnn4_test_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "    rnn4_test_acc /= len(test_dataloader)\n",
    "    rnn4_test_loss /= len(test_dataloader)\n",
    "print(f'rnn4:')\n",
    "print(f'     Test Loss: {rnn4_test_loss} | Test Acc:{rnn4_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add dropout GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n",
      "100%|██████████| 313/313 [00:03<00:00, 78.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.6788 | Train Acc: 55.96% | Val Loss: 0.6321 | Val Acc: 64.38%\n",
      "Saving model with loss: 0.6320838210257617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.5927 | Train Acc: 68.38% | Val Loss: 0.5353 | Val Acc: 73.26%\n",
      "Saving model with loss: 0.5353410921313546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 73.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.5528 | Train Acc: 71.87% | Val Loss: 0.5058 | Val Acc: 75.07%\n",
      "Saving model with loss: 0.5057668922977014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 72.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.5147 | Train Acc: 74.47% | Val Loss: 0.4789 | Val Acc: 77.34%\n",
      "Saving model with loss: 0.47888380695473065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.4889 | Train Acc: 76.20% | Val Loss: 0.4588 | Val Acc: 78.09%\n",
      "Saving model with loss: 0.45876811377026816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.4673 | Train Acc: 77.49% | Val Loss: 0.4522 | Val Acc: 78.44%\n",
      "Saving model with loss: 0.45216795937581494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 0.4530 | Train Acc: 78.50% | Val Loss: 0.4354 | Val Acc: 79.47%\n",
      "Saving model with loss: 0.4353807219727473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 0.4371 | Train Acc: 79.41% | Val Loss: 0.4318 | Val Acc: 79.55%\n",
      "Saving model with loss: 0.4318088265982541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 71.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 0.4195 | Train Acc: 80.58% | Val Loss: 0.4295 | Val Acc: 80.33%\n",
      "Saving model with loss: 0.4295097887516022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 0.4122 | Train Acc: 81.21% | Val Loss: 0.4160 | Val Acc: 81.25%\n",
      "Saving model with loss: 0.4159826588901607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 0.4020 | Train Acc: 81.33% | Val Loss: 0.4173 | Val Acc: 81.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 0.3948 | Train Acc: 81.83% | Val Loss: 0.4085 | Val Acc: 81.89%\n",
      "Saving model with loss: 0.40854953839020297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 78.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 0.3874 | Train Acc: 82.50% | Val Loss: 0.4026 | Val Acc: 81.18%\n",
      "Saving model with loss: 0.40257625552740967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 78.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 0.3815 | Train Acc: 82.94% | Val Loss: 0.3987 | Val Acc: 82.21%\n",
      "Saving model with loss: 0.39865960383957083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 71.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 0.3702 | Train Acc: 83.13% | Val Loss: 0.4048 | Val Acc: 82.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 0.3675 | Train Acc: 83.62% | Val Loss: 0.3910 | Val Acc: 82.60%\n",
      "Saving model with loss: 0.3910176479680972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 65.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss: 0.3617 | Train Acc: 83.71% | Val Loss: 0.4055 | Val Acc: 82.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 64.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss: 0.3577 | Train Acc: 83.99% | Val Loss: 0.3933 | Val Acc: 82.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 62.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss: 0.3493 | Train Acc: 84.83% | Val Loss: 0.3834 | Val Acc: 82.74%\n",
      "Saving model with loss: 0.3833817856555635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 73.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss: 0.3427 | Train Acc: 84.79% | Val Loss: 0.4103 | Val Acc: 82.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss: 0.3386 | Train Acc: 84.92% | Val Loss: 0.3763 | Val Acc: 83.45%\n",
      "Saving model with loss: 0.37629798359491606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 67.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss: 0.3303 | Train Acc: 85.49% | Val Loss: 0.3805 | Val Acc: 83.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss: 0.3259 | Train Acc: 85.56% | Val Loss: 0.3811 | Val Acc: 83.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 73.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss: 0.3186 | Train Acc: 86.03% | Val Loss: 0.3756 | Val Acc: 83.88%\n",
      "Saving model with loss: 0.3755704980682243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss: 0.3136 | Train Acc: 86.39% | Val Loss: 0.3897 | Val Acc: 83.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train Loss: 0.3153 | Train Acc: 86.20% | Val Loss: 0.3723 | Val Acc: 83.98%\n",
      "Saving model with loss: 0.3722907663746314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train Loss: 0.3081 | Train Acc: 86.56% | Val Loss: 0.3828 | Val Acc: 83.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train Loss: 0.3065 | Train Acc: 87.01% | Val Loss: 0.3810 | Val Acc: 83.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train Loss: 0.2966 | Train Acc: 87.30% | Val Loss: 0.3769 | Val Acc: 83.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Train Loss: 0.2935 | Train Acc: 87.11% | Val Loss: 0.3787 | Val Acc: 83.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 79.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Train Loss: 0.2898 | Train Acc: 87.32% | Val Loss: 0.3744 | Val Acc: 83.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Train Loss: 0.2870 | Train Acc: 87.61% | Val Loss: 0.3858 | Val Acc: 84.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 76.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Train Loss: 0.2780 | Train Acc: 88.30% | Val Loss: 0.3781 | Val Acc: 84.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 75.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Train Loss: 0.2751 | Train Acc: 88.08% | Val Loss: 0.3824 | Val Acc: 84.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Train Loss: 0.2774 | Train Acc: 88.11% | Val Loss: 0.3921 | Val Acc: 83.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 74.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Train Loss: 0.2731 | Train Acc: 88.31% | Val Loss: 0.3849 | Val Acc: 83.91%\n"
     ]
    }
   ],
   "source": [
    "rnn5 = SarcsmDetectorV4(vocab_size, embed_dim, hidden_dim, output_dim, p_drop=0.4).to(device)\n",
    "optimizer = torch.optim.Adam(rnn5.parameters(), lr = 0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "max_count = 10\n",
    "for epoch in range(num_epochs):\n",
    "    rnn5.train()\n",
    "    avg_train_loss = 0\n",
    "    train_acc = 0\n",
    "    for inputs, labels, lengths in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn5(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        avg_train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        train_acc += (outputs.round() == labels).sum().item()/len(labels)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc /= len(train_dataloader)\n",
    "    avg_train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Validate\n",
    "    avg_val_loss = 0\n",
    "    val_acc = 0\n",
    "    rnn5.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in val_dataloader:\n",
    "            inputs, labels = inputs.to(device) , labels.to(device)\n",
    "            \n",
    "            # Prediction\n",
    "            outputs = rnn5(inputs, lengths).squeeze()\n",
    "            \n",
    "            # Calculate and acumulate loss\n",
    "            loss = loss_fn(outputs, labels.float())\n",
    "            avg_val_loss += loss.item()\n",
    "\n",
    "            # Calculate acc\n",
    "            val_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "        val_acc /= len(val_dataloader)\n",
    "        avg_val_loss /= len(val_dataloader)\n",
    "    print(f'Epoch: {epoch} | Train Loss: {avg_train_loss:.4f} | Train Acc: {100*train_acc:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(rnn5.state_dict(), 'Saved Models/Sarcasm Det Models/best_rnn5.pth')\n",
    "        print(f'Saving model with loss: {avg_val_loss}')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter == max_count:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn5:\n",
      "     Test Loss: 0.3751916525404105 | Test Acc:0.8418188202247191\n"
     ]
    }
   ],
   "source": [
    "rnn5.load_state_dict(torch.load('Saved Models/Sarcasm Det Models/best_rnn5.pth'))\n",
    "\n",
    "rnn5.eval()\n",
    "rnn5_test_loss = 0\n",
    "rnn5_test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, lengths in test_dataloader:\n",
    "        inputs, labels = inputs.to(device) , labels.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        outputs = rnn5(inputs, lengths).squeeze()\n",
    "        \n",
    "        # Calculate and acumulate loss\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        rnn5_test_loss += loss.item()\n",
    "\n",
    "        # Calculate acc\n",
    "        rnn5_test_acc += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "\n",
    "    rnn5_test_acc /= len(test_dataloader)\n",
    "    rnn5_test_loss /= len(test_dataloader)\n",
    "print(f'rnn5:')\n",
    "print(f'     Test Loss: {rnn5_test_loss} | Test Acc:{rnn5_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_19196\\1524819709.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(non_pad, dtype = torch.float)\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "models = [rnn0, rnn1, rnn2, rnn3, rnn4, rnn5]\n",
    "model_accuracy = []\n",
    "model_loss = []\n",
    "for model in tqdm(models):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in test_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs, lengths).squeeze()\n",
    "            \n",
    "            correct += (outputs.round() == labels).sum().item()/len(inputs)\n",
    "            test_loss += loss_fn(outputs, labels).item()\n",
    "        model_accuracy.append(100*correct/len(test_dataloader))\n",
    "        model_loss.append(test_loss/len(test_dataloader))\n",
    "\n",
    "models_names = ['model0', 'model1', 'model2', 'model3', 'model4', 'modle5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bars =  ax.barh(models_names, model_accuracy)\n",
    "\n",
    "# Add labels to the bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()  # Get the width of the bar (i.e., the value)\n",
    "    ax.text(width-1, bar.get_y() + bar.get_height() / 2,\n",
    "            f'{np.round(width, 2)}%', ha='center', va='center', c = 'white')\n",
    "    \n",
    "ax.set_xlim(78, 85)\n",
    "ax.set_title('Accuracy of models')\n",
    "ax.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bars =  ax.barh(models_names, model_loss)\n",
    "\n",
    "# Add labels to the bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()  # Get the width of the bar (i.e., the value)\n",
    "    ax.text(width+0.005, bar.get_y() + bar.get_height() / 2,\n",
    "            f'{np.round(width, 3)}', ha='center', va='center')\n",
    "\n",
    "ax.set_xlim(0.36, 0.45)\n",
    "ax.set_title('Loss of models')\n",
    "ax.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
