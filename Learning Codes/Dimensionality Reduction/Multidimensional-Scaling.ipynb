{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Multidimensional-Scaling?\n",
    "Assume we have a 3 feature dataset with $N$ rows, we can represent all the points of this dataset in 3 dimensions. If we calculate the distance between each datapoint we end up with a distance matrix of shape $NxN$. With Multidimensional-scaling we are trying to represent this data in less dimensions (features) and getting a distance matrix as closest as the original. For this we use (as in PCA) linear algebra.\n",
    "\n",
    "In this case we will try to transform a 3 feature dataset into 2 feature dataset. The process for multidimensional-scaling goes as follows:\n",
    "\n",
    "1. Calculate the square-distance matrix $D^{2}$(remember this is a symmetric matix)\n",
    "\n",
    "2. Apply double centering:\n",
    "$$B = -\\frac{1}{2}CD^{2}C$$\n",
    "\n",
    "3. Get the eigenvalues and eigenvectors of $B$ and pick the $m$ largest eigenvalues ($m$ is the number of features we want to get).\n",
    "\n",
    "4. The new dataset is described by:\n",
    "$$X_{reduced} = E_{m}\\Lambda_{m}^{1/2}$$ \n",
    "\n",
    "where $E_{m}$ is the matrix of $m$ eigenvectors and $\\Lambda_{m}$ is the diagonal matrix of $m$ eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a dataset from sklearn.datasets.make_blob\n",
    "## Create sample dataset with sklearn \n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_samples = 10\n",
    "n_features = 3\n",
    "\n",
    "data =  make_blobs(n_samples = n_samples, \n",
    "                   n_features = n_features, \n",
    "                   centers = 1,\n",
    "                   random_state = 12)\n",
    "feature_data = data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate distance-saquared matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "D_squared = np.zeros((n_samples, n_samples))\n",
    "\n",
    "for ii in range(n_samples):\n",
    "    for jj in range(n_samples - ii - 1):\n",
    "        D_squared[ii, ii + jj + 1] = np.linalg.norm(feature_data[ii] - feature_data[ii + jj + 1])**2\n",
    "        D_squared[ii + jj + 1, ii] = D_squared[ii, ii + jj + 1] # Since the distance from A to B is the same from B to A \n",
    "                                                                # we don't need to calculate that again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply double centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Centering = np.identity(n_samples) - np.ones((n_samples, n_samples))/n_samples # Centering matrix\n",
    "\n",
    "B = -Centering@D_squared@Centering/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get eigenvectors and eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vec = np.linalg.eig(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the top 2 eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pos = np.argsort(eig_vals)[-2:][::-1]\n",
    "\n",
    "Em = np.transpose(eig_vec[max_pos])\n",
    "Lambda = np.diag(eig_vals[max_pos])\n",
    "\n",
    "X_reduced = Em@(Lambda**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets compare the distance matrices from the new X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX_squared = np.zeros((n_samples, n_samples))\n",
    "\n",
    "for ii in range(n_samples):\n",
    "    for jj in range(n_samples - ii - 1):\n",
    "        DX_squared[ii, ii + jj + 1] = np.linalg.norm(X_reduced[ii] - X_reduced[ii + jj + 1])**2\n",
    "        DX_squared[ii + jj + 1, ii] = DX_squared[ii, ii + jj + 1] # Since the distance from A to B is the same from B to A \n",
    "                                                                # we don't need to calculate that again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate stress \n",
    "\n",
    "We can calculate the performance of the MDs by getting the stress, which basically is adding the difference of the distances obtained between all points from the original to the new feature-space divided by the original distance squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456.25860180434665"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress = 0\n",
    "for ii in range(n_samples):\n",
    "    for jj in range(n_samples - ii - 1):\n",
    "        stress += ((D_squared[ii, ii + jj + 1] - DX_squared[ii, ii + jj + 1])/D_squared[ii, ii + jj + 1])**2\n",
    "stress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are creating a random dataset, preserving distances might be difficult when reducing dimensions, nevertheless this method tries to keep the differences at minimum and a 0 is usually not possible. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
